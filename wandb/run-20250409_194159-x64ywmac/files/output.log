[2025-04-09 19:42:02,575] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2025-04-09 19:42:02,575] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2025-04-09 19:42:02,575] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2025-04-09 19:42:02,575] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2025-04-09 19:42:02,575] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Epoch 0, Loss: 1.0, Positive Score: 0.490234375, Negative Score: 0.494140625
/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0, Loss: 0.953125, Positive Score: 0.46484375, Negative Score: 0.416015625
Epoch 0, Loss: 0.9609375, Positive Score: 0.427734375, Negative Score: 0.38671875
Epoch 0, Loss: 0.96484375, Positive Score: 0.443359375, Negative Score: 0.408203125
Epoch 0, Loss: 0.85546875, Positive Score: 0.423828125, Negative Score: 0.279296875
Epoch 0, Loss: 0.9375, Positive Score: 0.333984375, Negative Score: 0.271484375
Epoch 0, Loss: 0.8359375, Positive Score: 0.4375, Negative Score: 0.271484375
Epoch 0, Loss: 0.8359375, Positive Score: 0.408203125, Negative Score: 0.24609375
Epoch 0, Loss: 0.921875, Positive Score: 0.255859375, Negative Score: 0.1796875
Epoch 0, Loss: 0.60546875, Positive Score: 0.61328125, Negative Score: 0.21875
[2025-04-09 19:42:20,301] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:42:20,309] [INFO] [timer.py:215:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=0.6256095531440773, CurrSamplesPerSec=0.5651847699538615, MemAllocated=5.02GB, MaxMemAllocated=14.9GB
Epoch 0, Loss: 0.73046875, Positive Score: 0.47265625, Negative Score: 0.2021484375
Epoch 0, Loss: 0.78125, Positive Score: 0.455078125, Negative Score: 0.236328125
Epoch 0, Loss: 0.70703125, Positive Score: 0.53515625, Negative Score: 0.2431640625
Epoch 0, Loss: 0.51953125, Positive Score: 0.66015625, Negative Score: 0.1787109375
Epoch 0, Loss: 0.578125, Positive Score: 0.68359375, Negative Score: 0.26171875
Epoch 0, Loss: 0.50390625, Positive Score: 0.97265625, Negative Score: 0.4765625
Epoch 0, Loss: 0.65234375, Positive Score: 0.68359375, Negative Score: 0.3359375
Epoch 0, Loss: 0.01953125, Positive Score: 0.9921875, Negative Score: 0.01190185546875
Epoch 0, Loss: 0.67578125, Positive Score: 0.68359375, Negative Score: 0.359375
Epoch 0, Loss: 0.53125, Positive Score: 0.60546875, Negative Score: 0.134765625
[2025-04-09 19:42:32,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:42:32,407] [INFO] [timer.py:215:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=0.724595064724294, CurrSamplesPerSec=0.7865618318623718, MemAllocated=5.02GB, MaxMemAllocated=14.9GB
Epoch 0, Loss: 0.765625, Positive Score: 0.50390625, Negative Score: 0.271484375
Epoch 1, Loss: 0.55078125, Positive Score: 0.68359375, Negative Score: 0.234375
Epoch 1, Loss: 0.3359375, Positive Score: 0.6640625, Negative Score: 0.00074005126953125
Epoch 1, Loss: 0.328125, Positive Score: 0.96875, Negative Score: 0.296875
Epoch 1, Loss: 0.26953125, Positive Score: 0.7421875, Negative Score: 0.0098876953125
Epoch 1, Loss: 0.75, Positive Score: 0.5234375, Negative Score: 0.275390625
Epoch 1, Loss: 0.66015625, Positive Score: 0.53515625, Negative Score: 0.1943359375
Epoch 1, Loss: 0.7265625, Positive Score: 0.6640625, Negative Score: 0.388671875
Epoch 1, Loss: 0.5234375, Positive Score: 0.65234375, Negative Score: 0.1748046875
Epoch 1, Loss: 0.28125, Positive Score: 0.87109375, Negative Score: 0.1533203125
[2025-04-09 19:42:52,741] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:42:52,749] [INFO] [timer.py:215:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=0.712830897175775, CurrSamplesPerSec=1.3815831254850344, MemAllocated=5.02GB, MaxMemAllocated=14.9GB
Epoch 1, Loss: 0.328125, Positive Score: 0.68359375, Negative Score: 0.0101318359375
Epoch 1, Loss: 0.72265625, Positive Score: 0.53515625, Negative Score: 0.2578125
Epoch 1, Loss: 0.83984375, Positive Score: 0.578125, Negative Score: 0.41796875
Epoch 1, Loss: 0.46875, Positive Score: 0.80078125, Negative Score: 0.267578125
Epoch 1, Loss: 0.41796875, Positive Score: 0.73828125, Negative Score: 0.1572265625
Epoch 1, Loss: 0.71484375, Positive Score: 0.421875, Negative Score: 0.13671875
Epoch 1, Loss: 0.88671875, Positive Score: 0.63671875, Negative Score: 0.5234375
Epoch 1, Loss: 0.5, Positive Score: 0.6640625, Negative Score: 0.1650390625
Epoch 1, Loss: 0.609375, Positive Score: 0.392578125, Negative Score: 0.0034332275390625
Epoch 1, Loss: 0.5625, Positive Score: 0.64453125, Negative Score: 0.205078125
[2025-04-09 19:43:06,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:43:06,818] [INFO] [timer.py:215:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=0.7129551431396652, CurrSamplesPerSec=1.1657573454899801, MemAllocated=5.02GB, MaxMemAllocated=14.9GB
Epoch 1, Loss: 0.33203125, Positive Score: 0.9921875, Negative Score: 0.32421875
Epoch 1, Loss: 0.4765625, Positive Score: 0.5234375, Negative Score: 0.00087738037109375
Epoch 2, Loss: 0.17578125, Positive Score: 0.9765625, Negative Score: 0.1513671875
Epoch 2, Loss: 0.51171875, Positive Score: 0.828125, Negative Score: 0.33984375
Epoch 2, Loss: 0.54296875, Positive Score: 0.671875, Negative Score: 0.21484375
Epoch 2, Loss: 0.05078125, Positive Score: 1.0, Negative Score: 0.0517578125
Epoch 2, Loss: 0.40625, Positive Score: 0.83203125, Negative Score: 0.23828125
Epoch 2, Loss: 0.83984375, Positive Score: 0.294921875, Negative Score: 0.134765625
Epoch 2, Loss: 0.4453125, Positive Score: 0.71484375, Negative Score: 0.16015625
Epoch 2, Loss: 0.5, Positive Score: 0.5, Negative Score: 0.00018596649169921875
[2025-04-09 19:43:22,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:43:22,695] [INFO] [timer.py:215:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=0.6952693861708609, CurrSamplesPerSec=0.5451251357515345, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 2, Loss: 0.27734375, Positive Score: 0.7265625, Negative Score: 0.00421142578125
Epoch 2, Loss: 0.8359375, Positive Score: 0.166015625, Negative Score: 0.0003643035888671875
Epoch 2, Loss: 0.4765625, Positive Score: 0.6875, Negative Score: 0.1650390625
Epoch 2, Loss: 0.328125, Positive Score: 0.671875, Negative Score: 0.0016632080078125
Epoch 2, Loss: 0.01171875, Positive Score: 0.99609375, Negative Score: 0.00830078125
Epoch 2, Loss: 0.578125, Positive Score: 0.59375, Negative Score: 0.1708984375
Epoch 2, Loss: 0.0234375, Positive Score: 1.0, Negative Score: 0.023681640625
Epoch 2, Loss: 0.375, Positive Score: 0.8359375, Negative Score: 0.208984375
Epoch 2, Loss: 0.578125, Positive Score: 0.431640625, Negative Score: 0.011962890625
Epoch 2, Loss: 0.8046875, Positive Score: 0.6953125, Negative Score: 0.5
[2025-04-09 19:43:34,739] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:43:34,747] [INFO] [timer.py:215:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=0.7156437892080106, CurrSamplesPerSec=0.7403271112002279, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 2, Loss: 0.52734375, Positive Score: 0.68359375, Negative Score: 0.2109375
Epoch 2, Loss: 0.5234375, Positive Score: 0.84375, Negative Score: 0.3671875
Epoch 2, Loss: 0.38671875, Positive Score: 0.890625, Negative Score: 0.27734375
Epoch 3, Loss: 0.171875, Positive Score: 0.85546875, Negative Score: 0.02880859375
Epoch 3, Loss: 0.3046875, Positive Score: 0.8046875, Negative Score: 0.1083984375
Epoch 3, Loss: 0.1796875, Positive Score: 1.0, Negative Score: 0.177734375
Epoch 3, Loss: 0.40625, Positive Score: 1.0, Negative Score: 0.40625
Epoch 3, Loss: 0.56640625, Positive Score: 0.9453125, Negative Score: 0.51171875
Epoch 3, Loss: 0.2578125, Positive Score: 0.82421875, Negative Score: 0.08251953125
Epoch 3, Loss: 0.2578125, Positive Score: 1.0, Negative Score: 0.2578125
[2025-04-09 19:43:48,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:43:48,594] [INFO] [timer.py:215:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=0.7175884600075477, CurrSamplesPerSec=1.2655058488442612, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 3, Loss: 0.0078125, Positive Score: 0.9921875, Negative Score: 0.00011157989501953125
Epoch 3, Loss: 0.17578125, Positive Score: 0.82421875, Negative Score: 5.6743621826171875e-05
Epoch 3, Loss: 0.46484375, Positive Score: 0.53515625, Negative Score: 0.00010395050048828125
Epoch 3, Loss: 0.88671875, Positive Score: 0.1123046875, Negative Score: 2.9325485229492188e-05
Epoch 3, Loss: 0.79296875, Positive Score: 0.20703125, Negative Score: 9.5367431640625e-05
Epoch 3, Loss: 0.22265625, Positive Score: 0.77734375, Negative Score: 0.0002880096435546875
Epoch 3, Loss: 0.60546875, Positive Score: 0.5625, Negative Score: 0.1669921875
Epoch 3, Loss: 0.5625, Positive Score: 0.5703125, Negative Score: 0.130859375
Epoch 3, Loss: 0.50390625, Positive Score: 0.6640625, Negative Score: 0.1669921875
Epoch 3, Loss: 0.66796875, Positive Score: 0.57421875, Negative Score: 0.2412109375
[2025-04-09 19:44:03,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:44:03,226] [INFO] [timer.py:215:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=0.713296123015132, CurrSamplesPerSec=0.3363232176662576, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 3, Loss: 0.34375, Positive Score: 0.8359375, Negative Score: 0.1796875
Epoch 3, Loss: 0.02734375, Positive Score: 0.99609375, Negative Score: 0.0216064453125
Epoch 3, Loss: 0.21484375, Positive Score: 1.0, Negative Score: 0.21484375
Epoch 3, Loss: 0.4375, Positive Score: 0.66796875, Negative Score: 0.103515625
Epoch 4, Loss: 0.96875, Positive Score: 0.451171875, Negative Score: 0.421875
Epoch 4, Loss: 0.28125, Positive Score: 0.8359375, Negative Score: 0.1181640625
Epoch 4, Loss: 0.7109375, Positive Score: 0.8203125, Negative Score: 0.53125
Epoch 4, Loss: 0.1640625, Positive Score: 1.0, Negative Score: 0.166015625
Epoch 4, Loss: 0.1015625, Positive Score: 1.0, Negative Score: 0.099609375
Epoch 4, Loss: 0.50390625, Positive Score: 0.6640625, Negative Score: 0.1689453125
[2025-04-09 19:44:16,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:44:16,797] [INFO] [timer.py:215:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=0.7167142829219838, CurrSamplesPerSec=1.0657283651732814, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 4, Loss: 0.8515625, Positive Score: 0.2734375, Negative Score: 0.125
Epoch 4, Loss: 0.515625, Positive Score: 0.61328125, Negative Score: 0.126953125
Epoch 4, Loss: 0.640625, Positive Score: 0.6015625, Negative Score: 0.2412109375
Epoch 4, Loss: 0.33203125, Positive Score: 0.66796875, Negative Score: 0.0002803802490234375
Epoch 4, Loss: 0.4375, Positive Score: 0.73046875, Negative Score: 0.1669921875
Epoch 4, Loss: 0.3359375, Positive Score: 0.6640625, Negative Score: 9.250640869140625e-05
Epoch 4, Loss: 0.71875, Positive Score: 0.283203125, Negative Score: 5.4836273193359375e-05
Epoch 4, Loss: 0.3359375, Positive Score: 0.6640625, Negative Score: 5.0067901611328125e-05
Epoch 4, Loss: 0.54296875, Positive Score: 0.45703125, Negative Score: 0.00011682510375976562
Epoch 4, Loss: 0.703125, Positive Score: 0.421875, Negative Score: 0.12255859375
[2025-04-09 19:44:28,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:44:28,740] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=0.7276258375905356, CurrSamplesPerSec=1.047509111969459, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 4, Loss: 0.5703125, Positive Score: 0.431640625, Negative Score: 7.486343383789062e-05
Epoch 4, Loss: 0.5, Positive Score: 0.498046875, Negative Score: 0.00018596649169921875
Epoch 4, Loss: 0.5078125, Positive Score: 0.494140625, Negative Score: 0.0001392364501953125
Epoch 4, Loss: 0.48046875, Positive Score: 0.51953125, Negative Score: 0.00014591217041015625
Epoch 4, Loss: 0.7109375, Positive Score: 0.2890625, Negative Score: 0.0004634857177734375
Epoch 5, Loss: 0.5, Positive Score: 0.5, Negative Score: 0.00015163421630859375
Epoch 5, Loss: 0.83203125, Positive Score: 0.16796875, Negative Score: 0.000591278076171875
Epoch 5, Loss: 0.33203125, Positive Score: 0.66796875, Negative Score: 0.00017070770263671875
Epoch 5, Loss: 0.578125, Positive Score: 0.4296875, Negative Score: 0.008056640625
Epoch 5, Loss: 0.66796875, Positive Score: 0.5, Negative Score: 0.1669921875
[2025-04-09 19:44:42,741] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:44:42,749] [INFO] [timer.py:215:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=0.7269719203503088, CurrSamplesPerSec=1.2640683716790848, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 5, Loss: 0.22265625, Positive Score: 0.77734375, Negative Score: 0.0004482269287109375
Epoch 5, Loss: 0.5234375, Positive Score: 0.5, Negative Score: 0.025390625
Epoch 5, Loss: 0.484375, Positive Score: 0.65625, Negative Score: 0.1416015625
Epoch 5, Loss: 0.5, Positive Score: 0.5, Negative Score: 0.0004024505615234375
Epoch 5, Loss: 0.5078125, Positive Score: 0.490234375, Negative Score: 0.0002899169921875
Epoch 5, Loss: 0.66015625, Positive Score: 0.33984375, Negative Score: 0.000171661376953125
Epoch 5, Loss: 0.55859375, Positive Score: 0.5, Negative Score: 0.058837890625
Epoch 5, Loss: 0.49609375, Positive Score: 0.50390625, Negative Score: 0.00087738037109375
Epoch 5, Loss: 0.34765625, Positive Score: 0.65234375, Negative Score: 0.00057220458984375
Epoch 5, Loss: 0.28515625, Positive Score: 0.71484375, Negative Score: 0.000408172607421875
[2025-04-09 19:44:57,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:44:57,766] [INFO] [timer.py:215:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=0.7215654975529169, CurrSamplesPerSec=0.4044818041705474, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 5, Loss: 0.4296875, Positive Score: 0.5703125, Negative Score: 0.00024127960205078125
Epoch 5, Loss: 0.7890625, Positive Score: 0.4140625, Negative Score: 0.2021484375
Epoch 5, Loss: 0.8515625, Positive Score: 0.265625, Negative Score: 0.11865234375
Epoch 5, Loss: 0.30859375, Positive Score: 0.6953125, Negative Score: 0.0033721923828125
Epoch 5, Loss: 0.01171875, Positive Score: 0.98828125, Negative Score: 0.00131988525390625
Epoch 5, Loss: 0.37890625, Positive Score: 0.7109375, Negative Score: 0.09033203125
Epoch 6, Loss: 0.62890625, Positive Score: 0.408203125, Negative Score: 0.036376953125
Epoch 6, Loss: 0.5, Positive Score: 0.671875, Negative Score: 0.1708984375
Epoch 6, Loss: 0.48828125, Positive Score: 0.6953125, Negative Score: 0.1826171875
Epoch 6, Loss: 0.44140625, Positive Score: 0.65625, Negative Score: 0.0986328125
[2025-04-09 19:45:13,021] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:45:13,030] [INFO] [timer.py:215:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=0.7164675582767572, CurrSamplesPerSec=0.48693514421999146, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 6, Loss: 1.0390625, Positive Score: 0.173828125, Negative Score: 0.2099609375
Epoch 6, Loss: 1.015625, Positive Score: 0.337890625, Negative Score: 0.35546875
Epoch 6, Loss: 0.56640625, Positive Score: 0.5234375, Negative Score: 0.09033203125
Epoch 6, Loss: 0.16796875, Positive Score: 1.0, Negative Score: 0.1669921875
Epoch 6, Loss: 0.671875, Positive Score: 0.6640625, Negative Score: 0.333984375
Epoch 6, Loss: 0.421875, Positive Score: 0.6015625, Negative Score: 0.0244140625
Epoch 6, Loss: 0.328125, Positive Score: 0.671875, Negative Score: 0.000949859619140625
Epoch 6, Loss: 0.33203125, Positive Score: 0.66796875, Negative Score: 0.00029754638671875
Epoch 6, Loss: 0.484375, Positive Score: 0.515625, Negative Score: 0.00183868408203125
Epoch 6, Loss: 0.33203125, Positive Score: 0.66796875, Negative Score: 0.000782012939453125
[2025-04-09 19:45:26,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:45:26,275] [INFO] [timer.py:215:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=0.7192775523740919, CurrSamplesPerSec=0.9087183406974482, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 6, Loss: 0.234375, Positive Score: 0.89453125, Negative Score: 0.12890625
Epoch 6, Loss: 0.67578125, Positive Score: 0.498046875, Negative Score: 0.1728515625
Epoch 6, Loss: 0.3515625, Positive Score: 0.6484375, Negative Score: 0.0004558563232421875
Epoch 6, Loss: 0.40234375, Positive Score: 0.6328125, Negative Score: 0.036376953125
Epoch 6, Loss: 0.50390625, Positive Score: 0.66796875, Negative Score: 0.171875
Epoch 6, Loss: 0.20703125, Positive Score: 0.83203125, Negative Score: 0.03955078125
Epoch 6, Loss: 0.5, Positive Score: 0.66796875, Negative Score: 0.16796875
Epoch 7, Loss: 0.43359375, Positive Score: 0.58203125, Negative Score: 0.0174560546875
Epoch 7, Loss: 0.16796875, Positive Score: 1.0, Negative Score: 0.1689453125
Epoch 7, Loss: 0.49609375, Positive Score: 0.671875, Negative Score: 0.1669921875
[2025-04-09 19:45:40,346] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:45:40,354] [INFO] [timer.py:215:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=0.7192095490515622, CurrSamplesPerSec=0.6421431881644778, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 7, Loss: 0.421875, Positive Score: 0.9140625, Negative Score: 0.333984375
Epoch 7, Loss: 0.515625, Positive Score: 0.86328125, Negative Score: 0.37890625
Epoch 7, Loss: 0.36328125, Positive Score: 0.83203125, Negative Score: 0.1943359375
Epoch 7, Loss: 0.625, Positive Score: 1.0, Negative Score: 0.625
Epoch 7, Loss: 0.40625, Positive Score: 0.921875, Negative Score: 0.330078125
Epoch 7, Loss: 0.91796875, Positive Score: 0.859375, Negative Score: 0.77734375
Epoch 7, Loss: 1.09375, Positive Score: 0.7578125, Negative Score: 0.8515625
Epoch 7, Loss: 0.66796875, Positive Score: 1.0, Negative Score: 0.66796875
Epoch 7, Loss: 0.68359375, Positive Score: 0.83203125, Negative Score: 0.515625
Epoch 7, Loss: 0.79296875, Positive Score: 1.0, Negative Score: 0.79296875
[2025-04-09 19:45:55,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[1e-05, 1e-05], mom=[(0.9, 0.99), (0.9, 0.99)]
[2025-04-09 19:45:55,208] [INFO] [timer.py:215:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=0.7162518530881207, CurrSamplesPerSec=0.557388739304367, MemAllocated=5.02GB, MaxMemAllocated=16.5GB
Epoch 7, Loss: 0.73046875, Positive Score: 0.93359375, Negative Score: 0.6640625
Epoch 7, Loss: 0.796875, Positive Score: 1.0, Negative Score: 0.796875
Epoch 7, Loss: 0.98828125, Positive Score: 0.83203125, Negative Score: 0.8203125
Epoch 7, Loss: 0.3359375, Positive Score: 1.0, Negative Score: 0.333984375
Epoch 7, Loss: 0.16796875, Positive Score: 1.0, Negative Score: 0.1669921875
Epoch 7, Loss: 0.75, Positive Score: 1.0, Negative Score: 0.75
Epoch 7, Loss: 0.859375, Positive Score: 1.0, Negative Score: 0.859375
Epoch 7, Loss: 0.3203125, Positive Score: 0.84765625, Negative Score: 0.1669921875
Epoch 8, Loss: 0.79296875, Positive Score: 1.0, Negative Score: 0.79296875
Traceback (most recent call last):
  File "/home/li/MachineLr/RWKV-Development-Tools-ssg/wkv7_reward_model/train_model.py", line 255, in <module>
    model_engine.backward(Loss)
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 1862, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1901, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/autograd/function.py", line 289, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 658, in backward
    outputs = ctx.run_function(*detached_inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/MachineLr/RWKV-Development-Tools-ssg/wkv7_reward_model/model/block.py", line 27, in forward
    x_attn, v_first = self.att(
                      ^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/MachineLr/RWKV-Development-Tools-ssg/wkv7_reward_model/model/att.py", line 159, in forward
    x = RUN_CUDA_RWKV7g(r, w, k, v, -kk, kk * a)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/MachineLr/RWKV-Development-Tools-ssg/wkv7_reward_model/model/rwkvop.py", line 57, in RUN_CUDA_RWKV7g
    return WindBackstepping.apply(w, q, k, v, a, b).view(B, T, HC)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/anaconda3/envs/LLMs/lib/python3.11/site-packages/torch/autograd/function.py", line 553, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/li/MachineLr/RWKV-Development-Tools-ssg/wkv7_reward_model/model/rwkvop.py", line 34, in forward
    s = torch.empty(
        ^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.75 GiB. GPU 0 has a total capacity of 23.68 GiB of which 6.16 GiB is free. Including non-PyTorch memory, this process has 17.36 GiB memory in use. Of the allocated memory 10.64 GiB is allocated by PyTorch, and 6.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)